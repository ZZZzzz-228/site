import requests
import time
import pymysql
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import re
from datetime import datetime

DB_CONFIG = {
    "host": "localhost",
    "user": "root",
    "password": "Ze2Ma2==03",
    "database": "city_db",
    "charset": "utf8mb4",
    "cursorclass": pymysql.cursors.DictCursor
}

BASE_URL = "http://005–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫.—Ä—Ñ/"

MONTHS_RU = {
    "—è–Ω–≤–∞—Ä—è": "01", "—Ñ–µ–≤—Ä–∞–ª—è": "02", "–º–∞—Ä—Ç–∞": "03", "–∞–ø—Ä–µ–ª—è": "04",
    "–º–∞—è": "05", "–∏—é–Ω—è": "06", "–∏—é–ª—è": "07", "–∞–≤–≥—É—Å—Ç–∞": "08",
    "—Å–µ–Ω—Ç—è–±—Ä—è": "09", "–æ–∫—Ç—è–±—Ä—è": "10", "–Ω–æ—è–±—Ä—è": "11", "–¥–µ–∫–∞–±—Ä—è": "12"
}

def get_connection():
    return pymysql.connect(**DB_CONFIG)

def save_to_db(item):
    conn = get_connection()
    cur = conn.cursor()
    cur.execute(
        "SELECT id FROM outages WHERE title=%s AND date=%s AND district=%s",
        (item["title"], item["date"], item["district"])
    )
    if cur.fetchone() is None:
        cur.execute(
            """INSERT INTO outages
               (type, date, title, link,
                start_date, end_date, address, district)
               VALUES (%s,%s,%s,%s,%s,%s,%s,%s)""",
            (
                item["type"], item["date"], item["title"], item["link"],
                item["start_date"], item["end_date"], item["address"], item["district"]
            )
        )
        conn.commit()
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {item['title']} ({item['district']})")
    else:
        print(f"‚ö†Ô∏è –£–∂–µ –µ—Å—Ç—å: {item['title']} ({item['district']})")
    cur.close()
    conn.close()

def normalize_date(raw):
    try:
        parts = raw.strip().split()
        if len(parts) >= 2:
            day = parts[0]
            month = MONTHS_RU.get(parts[1].lower(), "??")
            if month != "??":
                return f"{day.zfill(2)}.{month}"
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å –¥–∞—Ç—É: {raw}")
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞—Ç—ã: {raw} ‚Äî {e}")

def parse_005():
    print("üì° –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É...")
    resp = requests.get(BASE_URL, headers={"User-Agent": "Mozilla/5.0"})
    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")

    tabs = soup.select(".elementor-tabs-wrapper .elementor-tab-title")
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ –≤–∫–ª–∞–¥–æ–∫: {len(tabs)}")

    total_saved = 0
    for tab in tabs:
        content = soup.select_one(f".elementor-tab-content[data-tab='{tab['data-tab']}']")
        if not content:
            continue
        iframe = content.find("iframe", src=True)
        if not iframe:
            continue

        iframe_url = urljoin(BASE_URL, iframe["src"])
        print(f"üåê –ó–∞–≥—Ä—É–∂–∞–µ–º iframe: {iframe_url}")
        page = requests.get(iframe_url, headers={"User-Agent": "Mozilla/5.0"})
        page.encoding = "cp1251"
        frame = BeautifulSoup(page.text, "html.parser")
        table = frame.find("table")
        if not table:
            continue

        current_district = None
        for tr in table.select("tr"):
            for td in tr.select("td"):
                style = td.get("style", "").lower()
                txt = td.get_text(strip=True).lower()
                if "background:#0069d2" in style and "—Ä–∞–π–æ–Ω" in txt:
                    current_district = td.get_text(strip=True)
                    break
            else:
                pass
            if current_district and any("background:#0069d2" in td.get("style", "").lower() for td in tr.select("td")):
                continue
            if current_district is None:
                continue

            cells = tr.select("td")
            if len(cells) != 3:
                continue

            parts = list(cells[0].stripped_strings)
            if not parts:
                continue
            service = parts[0]
            skip = {
                "—Ä–µ—Å—É—Ä—Å", "–∞–¥—Ä–µ—Å–∞ –ø—Ä–∏—á–∏–Ω–∞", "–Ω–∞—á–∞–ª–æ - –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ",
                "–∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –Ω–∞ –∑–∞–≤—Ç—Ä–∞"
            }
            if service.lower() in skip:
                continue
            org = ", ".join(parts[1:]) if len(parts) > 1 else ""
            title = f"{service} ‚Äî {org}".strip(" ‚Äî")

            address = " ".join(cells[1].stripped_strings)
            times = list(cells[2].stripped_strings)
            if not times:
                continue
            start = times[0]
            end = times[1] if len(times) > 1 else ""

            try:
                date = normalize_date(start)
            except Exception as e:
                print(f"‚ùå {e}")
                continue

            save_to_db({
                "type":       service,
                "date":       date,
                "title":      title,
                "link":       iframe_url,
                "start_date": start,
                "end_date":   end,
                "address":    address,
                "district":   current_district
            })
            total_saved += 1

    print(f"\nüì• –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {total_saved}")

if __name__ == "__main__":
    print("üîÅ –ü–∞—Ä—Å–µ—Ä –∑–∞–ø—É—â–µ–Ω –≤ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–º —Ü–∏–∫–ª–µ. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 2 –º–∏–Ω—É—Ç—ã.")
    while True:
        try:
            parse_005()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
        print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 2 –º–∏–Ω—É—Ç—ã...\n")
        time.sleep(120)
